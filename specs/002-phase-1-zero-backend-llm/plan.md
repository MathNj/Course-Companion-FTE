# Implementation Plan: Phase 1 - Zero-Backend-LLM Course Companion

**Branch**: `002-phase-1-zero-backend-llm` | **Date**: 2026-01-24 | **Spec**: [spec.md](./spec.md)
**Input**: Feature specification from `/specs/002-phase-1-zero-backend-llm/spec.md`

## Summary

Build a deterministic backend API and ChatGPT App for delivering Generative AI Fundamentals course content through conversational interface. Backend serves pre-authored content from Cloudflare R2 with ZERO LLM inference (constitutional requirement). Students access 6 chapters, take rule-based quizzes, track progress, and navigate freemium gating (Chapters 1-3 free, 4-6 premium). Four Agent Skills (concept-explainer, quiz-master, socratic-tutor, progress-motivator) provide structured conversational guidance. Cost target: <$0.004/user/month. Architecture achieves near-zero marginal cost by delegating all intelligence to ChatGPT where users already pay for access.

## Technical Context

**Language/Version**: Python 3.11+ (for async/await, match statements, improved type hints)
**Primary Dependencies**:
- FastAPI 0.104+ (web framework with auto OpenAPI docs, Pydantic v2 validation)
- SQLAlchemy 2.0+ (async ORM for PostgreSQL)
- Pydantic v2 (request/response validation, settings management)
- httpx (async HTTP client for R2 access)
- python-jose[cryptography] (JWT token generation/validation)
- passlib[bcrypt] (password hashing)
- redis-py (async Redis client for caching)
- boto3 (Cloudflare R2 S3-compatible client)
- alembic (database migrations)

**Storage**:
- **Content**: Cloudflare R2 (course chapters, quizzes, media - S3-compatible API)
- **Database**: PostgreSQL 15+ via Neon or Supabase (user data, progress, quiz attempts, subscriptions)
- **Cache**: Redis 7+ via Upstash or Redis Cloud (session data, frequently accessed content)

**Testing**:
- pytest 7.0+ (unit and integration tests)
- pytest-asyncio (async test support)
- httpx (TestClient for FastAPI endpoint testing)
- pytest-cov (code coverage reports, target >80%)
- Zero-LLM verification test (custom fixture to mock LLM endpoints)

**Target Platform**: Linux server (containerized deployment on Fly.io or Railway)
**Project Type**: Web application (backend API + ChatGPT App frontend)
**Performance Goals**:
- <1 second API response time (p95 latency) for content delivery
- <100ms for deterministic operations (quiz grading, progress updates)
- Support 10,000 concurrent users without degradation
- <$40/month infrastructure cost for 10,000 users ($0.004/user/month)

**Constraints**:
- ZERO LLM API calls in backend (constitutional requirement)
- All content must be served verbatim from R2 storage
- Quiz grading must use answer keys and rule-based logic only
- Progress sync across devices within 5 seconds

**Scale/Scope**:
- 6 course chapters with estimated 10-15 sections each
- 6 quizzes (10 questions each: 5 MC, 3 T/F, 2 short-answer)
- Expected 10,000+ students at launch
- 4 Agent Skills (SKILL.md files with procedural knowledge)
- 19 REST API endpoints (15 v1 deterministic)

## Constitution Check

*GATE: Must pass before Phase 0 research. Re-checked after Phase 1 design.*

### Gate I: Zero-Backend-LLM First (Phase 1) - âœ… PASS

**Status**: PASS
**Evidence**:
- Specification explicitly states FR-036: "Backend APIs MUST make ZERO calls to LLM services"
- FR-037: All content served from pre-authored materials in R2 storage
- FR-038: Automated verification test required to detect any LLM API calls
- Architecture delegates all intelligence to ChatGPT via OpenAI Apps SDK
- Quiz grading uses answer keys (FR-013), not LLM inference
- Search uses keyword matching (FR-004), not LLM summarization

**Verification Strategy**:
- Implement `tests/test_v1_deterministic.py` with LLM endpoint mocking
- Mock OpenAI/Anthropic API endpoints to raise exceptions if called
- Run test suite in CI/CD as blocking check before deployment
- Code review checklist includes "Zero-LLM compliance verified"

---

### Gate II: Cost Efficiency & Scalability - âœ… PASS

**Status**: PASS
**Cost Targets**:
- Phase 1 target: <$0.004/user/month
- Infrastructure target: <$50/month for 10,000 users

**Cost Breakdown (Projected)**:
| Component | Provider | Monthly Cost (10K users) | Per-User Cost |
|-----------|----------|-------------------------|---------------|
| Compute | Fly.io/Railway | $10-20 | $0.001-$0.002 |
| Database | Neon Free Tier | $0-25 | $0-$0.0025 |
| Cache | Redis Cloud Free | $0-10 | $0-$0.001 |
| Storage | Cloudflare R2 | $5 (10GB + 100K reads) | $0.0005 |
| **TOTAL** | | **$15-60** | **$0.0015-$0.006** |

**Rationale**: Cost target met by leveraging free tiers (Neon, Redis Cloud) and R2's zero egress pricing. ChatGPT usage cost borne by users ($20/month ChatGPT Plus), not by our infrastructure.

**Scalability Evidence**:
- FR-040: Caching reduces storage API calls
- FR-041: System designed for 10,000+ concurrent users
- Database indexes on user_id, chapter_id, quiz_id for fast lookups
- Content cached at edge (R2 + Redis) for sub-100ms latency

---

### Gate III: Spec-Driven Development - âœ… PASS

**Status**: PASS
**Artifacts Created**:
- âœ… spec.md: 5 user stories (P1), 41 FR, 20 SC, 9 entities
- âœ… plan.md: This file (technical context, architecture, constitutional check)
- ðŸ”„ research.md: To be generated in Phase 0 (below)
- ðŸ”„ data-model.md: To be generated in Phase 1 (below)
- ðŸ”„ contracts/: To be generated in Phase 1 (below)
- ðŸ”„ quickstart.md: To be generated in Phase 1 (below)
- â³ tasks.md: To be generated via `/sp.tasks` command

**Traceability**:
- Every user story (US1-US5) has Given/When/Then acceptance scenarios
- All functional requirements (FR-001 to FR-041) are testable
- Success criteria (SC-001 to SC-020) are measurable and technology-agnostic
- All design artifacts trace back to FR and SC from spec

---

### Gate IV: Hybrid Intelligence Isolation - âœ… PASS (N/A for Phase 1)

**Status**: PASS (Not Applicable - Phase 1 is pure deterministic)
**Justification**: Phase 1 has ZERO hybrid features. All v1 APIs (`/api/v1/*`) are deterministic. Phase 2 will add `/api/v2/*` endpoints with complete isolation.

**Architecture Preparation for Phase 2**:
- Separate router modules: `backend/app/api/v1/` (deterministic) vs `backend/app/api/v2/` (future hybrid)
- Middleware ready: `verify_premium` dependency for premium-gating
- Cost tracking infrastructure: LLM usage logging table designed but unused in Phase 1

---

### Gate V: Educational Delivery Excellence - âœ… PASS

**Status**: PASS
**Evidence**:
- 6 chapters structured per constitutional requirements (FR-001, FR-002)
- 4 mandatory Agent Skills specified (FR-006 to FR-011): concept-explainer, quiz-master, socratic-tutor, progress-motivator
- Quiz design follows requirements: 5 MC + 3 T/F + 2 short-answer per chapter (FR-012)
- Progress tracking persists across sessions (FR-022)
- Streak calculations timezone-aware (FR-025)

**Content Quality Requirements**:
- Course content authored by subject matter experts (Assumption 1 in spec)
- Quiz answer keys validated before storage in R2
- Explanations grounded in course content (no hallucinations per FR-037)
- Agent Skills reference backend APIs explicitly (detailed in SKILL.md files)

---

### Gate VI: Agent Skills & MCP Integration - âœ… PASS

**Status**: PASS
**Agent Skills (4 Mandatory)**:
1. **concept-explainer**: Multi-level explanations (beginner/intermediate/advanced) from pre-authored content
2. **quiz-master**: Quiz guidance with encouragement, answer explanations from quiz metadata
3. **socratic-tutor**: Guiding questions without direct answers, building on student knowledge
4. **progress-motivator**: Milestone celebrations, specific praise, next goal suggestions

**SKILL.md Structure** (per constitutional requirements):
- Metadata: Name, trigger keywords, purpose
- Purpose: What skill accomplishes
- Workflow: Step-by-step procedure
- Response Templates: Example outputs
- Key Principles: Guidelines and constraints

**MCP Usage in Phase 1**:
- MCP servers not directly used in Phase 1 (ChatGPT handles intelligence)
- Backend APIs serve as MCP-like tool layer for ChatGPT
- Future Phase 2 may integrate MCP for complex workflows

---

### Gate VII: Security & Secrets Management - âœ… PASS

**Status**: PASS
**Security Measures**:
- FR-031 to FR-035: User authentication with email/password, JWT tokens, password reset
- FR-029: Subscription verification on every content request
- Secrets stored in `.env` file (gitignored), never hardcoded
- Production secrets via Fly.io/Railway secret management
- Passwords hashed with bcrypt (passlib)
- JWT tokens signed with secret key, 30-day expiration
- Rate limiting planned (FR-041: 10,000 concurrent users)

**Data Privacy**:
- User data isolated per user_id (database row-level isolation)
- No PII logged in application logs
- Progress data encrypted at rest (database level)

---

### Gate VIII: Testing & Quality Gates - âœ… PASS

**Status**: PASS
**Testing Requirements**:
- pytest with >80% code coverage target
- Unit tests for all business logic (quiz grading, progress calculations)
- Integration tests for all API endpoints (FastAPI TestClient)
- Zero-LLM verification test (custom fixture mocking LLM endpoints)

**Quality Gates** (CI/CD pipeline):
1. All tests passing (pytest --cov=backend/app --cov-report=term-missing)
2. Zero-LLM test passing (tests/test_v1_deterministic.py)
3. Code review approved (1+ reviewer)
4. Constitutional compliance checklist completed in PR

---

### Gate IX: Technology Stack Constraints - âœ… PASS

**Status**: PASS
**Technology Choices** (all constitutional-compliant):
- **Backend**: Python 3.11+, FastAPI 0.104+, SQLAlchemy 2.0+, Pydantic v2 âœ…
- **Database**: PostgreSQL via Neon or Supabase âœ…
- **Cache**: Redis via Upstash or Redis Cloud âœ…
- **Storage**: Cloudflare R2 (S3-compatible) âœ…
- **ChatGPT Integration**: OpenAI Apps SDK (manifest.yaml + system prompts) âœ…
- **Infrastructure**: Fly.io or Railway (containerized) âœ…
- **CI/CD**: GitHub Actions âœ…

---

### Gate X: Development Workflow - âœ… PASS

**Status**: PASS
**Workflow Compliance**:
- Feature branch: `002-phase-1-zero-backend-llm` âœ…
- Spec created: `specs/002-phase-1-zero-backend-llm/spec.md` âœ…
- Plan being created: `specs/002-phase-1-zero-backend-llm/plan.md` (this file) âœ…
- Next: Tasks will be created via `/sp.tasks` command
- Commit messages will follow format: `type(scope): description` with Co-Authored-By footer
- PHR will be created after planning completion

---

**Constitution Check Summary**: âœ… **10/10 GATES PASSED**
**Proceed to Phase 0: Research**

## Project Structure

### Documentation (this feature)

```text
specs/002-phase-1-zero-backend-llm/
â”œâ”€â”€ spec.md              # Feature specification (completed)
â”œâ”€â”€ plan.md              # This file (in progress)
â”œâ”€â”€ research.md          # Phase 0 output (generated below)
â”œâ”€â”€ data-model.md        # Phase 1 output (generated below)
â”œâ”€â”€ quickstart.md        # Phase 1 output (generated below)
â”œâ”€â”€ contracts/           # Phase 1 output (generated below)
â”‚   â””â”€â”€ README.md        # API endpoint documentation
â”œâ”€â”€ checklists/          # Quality validation
â”‚   â””â”€â”€ requirements.md  # Spec quality checklist (completed)
â””â”€â”€ tasks.md             # Phase 2 output (/sp.tasks command - NOT created by /sp.plan)
```

### Source Code (repository root)

```text
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py              # FastAPI application entry point
â”‚   â”œâ”€â”€ config.py            # Settings (Pydantic BaseSettings)
â”‚   â”œâ”€â”€ database.py          # SQLAlchemy async engine, sessionmaker
â”‚   â”œâ”€â”€ dependencies.py      # Auth middleware, premium verification
â”‚   â”‚
â”‚   â”œâ”€â”€ models/              # SQLAlchemy ORM models
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ user.py          # Student, Subscription
â”‚   â”‚   â”œâ”€â”€ progress.py      # ChapterProgress, Streak
â”‚   â”‚   â””â”€â”€ quiz.py          # QuizAttempt
â”‚   â”‚
â”‚   â”œâ”€â”€ schemas/             # Pydantic request/response models
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ user.py          # UserCreate, UserResponse, Token
â”‚   â”‚   â”œâ”€â”€ progress.py      # ProgressResponse, StreakResponse
â”‚   â”‚   â””â”€â”€ quiz.py          # QuizResponse, QuizSubmission, QuizResult
â”‚   â”‚
â”‚   â”œâ”€â”€ api/                 # REST endpoints
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ v1/              # Phase 1 deterministic endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ auth.py      # POST /auth/register, /auth/login, /auth/refresh
â”‚   â”‚   â”‚   â”œâ”€â”€ chapters.py  # GET /v1/chapters, /v1/chapters/{id}
â”‚   â”‚   â”‚   â”œâ”€â”€ quizzes.py   # GET /v1/quizzes/{id}, POST /v1/quizzes/{id}/submit
â”‚   â”‚   â”‚   â”œâ”€â”€ progress.py  # GET /v1/progress, PUT /v1/progress/chapter/{id}
â”‚   â”‚   â”‚   â””â”€â”€ access.py    # GET /v1/access/check
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ v2/              # Phase 2 hybrid endpoints (future)
â”‚   â”‚       â””â”€â”€ __init__.py  # Placeholder for future expansion
â”‚   â”‚
â”‚   â”œâ”€â”€ services/            # Business logic
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ content.py       # R2 content retrieval, caching
â”‚   â”‚   â”œâ”€â”€ quiz_grader.py   # Deterministic grading logic
â”‚   â”‚   â”œâ”€â”€ progress_tracker.py # Streak calculations, completion %
â”‚   â”‚   â””â”€â”€ auth.py          # JWT creation, password hashing
â”‚   â”‚
â”‚   â”œâ”€â”€ skills/              # Agent Skills (SKILL.md files)
â”‚   â”‚   â”œâ”€â”€ concept-explainer/
â”‚   â”‚   â”‚   â””â”€â”€ SKILL.md
â”‚   â”‚   â”œâ”€â”€ quiz-master/
â”‚   â”‚   â”‚   â””â”€â”€ SKILL.md
â”‚   â”‚   â”œâ”€â”€ socratic-tutor/
â”‚   â”‚   â”‚   â””â”€â”€ SKILL.md
â”‚   â”‚   â””â”€â”€ progress-motivator/
â”‚   â”‚       â””â”€â”€ SKILL.md
â”‚   â”‚
â”‚   â””â”€â”€ utils/               # Utilities
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ storage.py       # Cloudflare R2 client wrapper
â”‚       â””â”€â”€ cache.py         # Redis client wrapper
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py          # Pytest fixtures (test DB, mock R2, mock LLMs)
â”‚   â”œâ”€â”€ test_v1_deterministic.py # CRITICAL: Zero-LLM verification
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ test_auth.py
â”‚   â”‚   â”œâ”€â”€ test_chapters.py
â”‚   â”‚   â”œâ”€â”€ test_quizzes.py
â”‚   â”‚   â””â”€â”€ test_progress.py
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ test_quiz_grader.py
â”‚   â”‚   â””â”€â”€ test_progress_tracker.py
â”‚   â””â”€â”€ models/
â”‚       â””â”€â”€ test_user.py
â”‚
â”œâ”€â”€ alembic/                 # Database migrations
â”‚   â”œâ”€â”€ versions/
â”‚   â””â”€â”€ env.py
â”‚
â”œâ”€â”€ content/                 # Course content (JSON files for local dev)
â”‚   â”œâ”€â”€ chapters/
â”‚   â”‚   â”œâ”€â”€ 01-intro-genai.json
â”‚   â”‚   â”œâ”€â”€ 02-llms.json
â”‚   â”‚   â”œâ”€â”€ 03-prompting.json
â”‚   â”‚   â”œâ”€â”€ 04-rag.json
â”‚   â”‚   â”œâ”€â”€ 05-fine-tuning.json
â”‚   â”‚   â””â”€â”€ 06-ai-applications.json
â”‚   â””â”€â”€ quizzes/
â”‚       â”œâ”€â”€ 01-quiz.json
â”‚       â”œâ”€â”€ 02-quiz.json
â”‚       â”œâ”€â”€ 03-quiz.json
â”‚       â”œâ”€â”€ 04-quiz.json
â”‚       â”œâ”€â”€ 05-quiz.json
â”‚       â””â”€â”€ 06-quiz.json
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ seed_content.py      # Upload content to R2
â”‚   â””â”€â”€ create_test_user.py  # Create test user for development
â”‚
â”œâ”€â”€ .env.example             # Environment variable template
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ requirements-dev.txt     # Development dependencies (pytest, etc.)
â”œâ”€â”€ pyproject.toml           # Project metadata, Black/isort config
â”œâ”€â”€ Dockerfile               # Container image for deployment
â”œâ”€â”€ fly.toml                 # Fly.io configuration (if using Fly.io)
â””â”€â”€ README.md                # Backend-specific documentation

chatgpt-app/
â”œâ”€â”€ manifest.yaml            # OpenAI App definition
â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ _shared-context.txt  # Shared grounding for all modes
â”‚   â”œâ”€â”€ teach.txt            # concept-explainer mode prompt
â”‚   â”œâ”€â”€ quiz.txt             # quiz-master mode prompt
â”‚   â”œâ”€â”€ socratic.txt         # socratic-tutor mode prompt
â”‚   â””â”€â”€ motivation.txt       # progress-motivator mode prompt
â”‚
â””â”€â”€ README.md                # ChatGPT App setup instructions

docker-compose.yml           # Local PostgreSQL + Redis for development
.github/
â””â”€â”€ workflows/
    â””â”€â”€ ci.yml               # GitHub Actions CI/CD pipeline
```

**Structure Decision**: Web application architecture with separate `backend/` and `chatgpt-app/` directories. Backend is a standalone FastAPI application that serves RESTful APIs. ChatGPT App is the frontend interface that calls backend APIs. This structure enables future Phase 3 web app to reuse the same backend APIs.

## Complexity Tracking

> **No constitutional violations requiring justification. All gates passed.**

This section is intentionally left blank because the Phase 1 architecture fully complies with all constitutional principles without introducing any prohibited complexity.

## Phase 0: Research

### Research Questions

Based on Technical Context unknowns and technology choices, the following research questions must be resolved:

**R1: Cloudflare R2 Integration Best Practices**
- **Question**: What are the optimal patterns for integrating Cloudflare R2 with FastAPI for content delivery?
- **Decision**: Use boto3 (AWS SDK) with Cloudflare R2 endpoints. R2 is S3-compatible, so boto3 works seamlessly. For local development, use MinIO or localstack for S3-compatible testing. For caching, combine R2 with Redis to reduce API calls.
- **Rationale**: boto3 is mature, well-documented, and S3-compatible. R2's zero egress pricing makes it ideal for frequent content delivery. Redis caching layer reduces latency to <100ms for frequently accessed chapters.
- **Alternatives Considered**:
  - Direct HTTP requests to R2: Rejected (requires manual signing, boto3 handles this)
  - PostgreSQL JSONB for content: Rejected (expensive at scale, R2 cheaper for large content)

**R2: ChatGPT Apps SDK Integration Pattern**
- **Question**: How should system prompts be structured for 4 Agent Skills in ChatGPT Apps?
- **Decision**: Create separate prompt files per skill mode (`teach.txt`, `quiz.txt`, `socratic.txt`, `motivation.txt`) with shared context preamble (`_shared-context.txt`). ChatGPT routes to appropriate prompt based on trigger keywords. Each prompt references backend API actions explicitly.
- **Rationale**: Modular prompts enable independent testing and updates per skill. Shared context ensures consistency in grounding (course content, no hallucinations). Clear API action references in prompts ensure predictable backend calls.
- **Alternatives Considered**:
  - Single mega-prompt with all skills: Rejected (hard to maintain, prone to context leakage)
  - Dynamic prompt generation: Rejected (complexity, Phase 1 is deterministic)

**R3: Quiz Grading Logic Implementation**
- **Question**: How to implement deterministic quiz grading for multiple-choice, true/false, and short-answer questions?
- **Decision**:
  - **Multiple-choice**: Exact string match against answer key (case-insensitive)
  - **True/False**: Boolean comparison
  - **Short-answer**: Keyword matching with partial credit (0-10 scale based on keyword presence). Short-answer grading in Phase 1 is basic; Phase 2 will use LLM for nuanced evaluation.
- **Rationale**: Simple, fast, deterministic. Meets FR-013 (deterministic grading) and FR-014 (percentage score). Keyword matching for short-answer provides reasonable Phase 1 experience without LLM complexity.
- **Alternatives Considered**:
  - Manual grading by instructors: Rejected (Phase 1 is self-service)
  - Fuzzy string matching: Rejected (over-engineering for Phase 1)

**R4: Progress Tracking & Streak Calculation**
- **Question**: How to implement timezone-aware streak calculations that work globally?
- **Decision**: Store user timezone in database (FR-025 requirement). Calculate "active day" based on user's local midnight, not server time. Use Python's `zoneinfo` module for timezone handling. Streak increments if activity exists within user's local calendar day.
- **Rationale**: Accurate streaks are critical for motivation (SC-009: 80% return rate for milestone celebrations). Server-time streaks would penalize users in different timezones. `zoneinfo` is standard library in Python 3.9+, no external dependency.
- **Alternatives Considered**:
  - UTC-only streaks: Rejected (unfair to global users)
  - Client-side timezone detection: Rejected (unreliable, users can spoof)

**R5: Freemium Access Control Enforcement**
- **Question**: How to enforce freemium gating at API level while maintaining good UX?
- **Decision**: Implement middleware dependency `verify_access(chapter_id: str, user: User)` that checks:
  1. Chapter 1-3: Always accessible
  2. Chapter 4-6: Check `user.subscription_tier == 'premium'`
  3. Return 403 Forbidden with upgrade message if unauthorized
- **Rationale**: Middleware approach is clean, testable, and consistent across all content endpoints. Returning structured error with upgrade CTA enables graceful UX in ChatGPT App.
- **Alternatives Considered**:
  - Frontend-only gating: Rejected (insecure, easily bypassed)
  - Database-level row security: Rejected (over-engineering for Phase 1)

**R6: Session Management & JWT Strategy**
- **Question**: What JWT claims and expiration policy should be used?
- **Decision**: JWT payload includes: `user_id`, `email`, `subscription_tier`, `exp` (30-day expiration). Access token valid for 30 days (Assumption 3 in spec). Refresh token not implemented in Phase 1 (users re-authenticate after 30 days). Tokens signed with HS256 algorithm, secret key in `.env`.
- **Rationale**: 30-day expiration balances security (automatic logout after inactivity) and UX (students don't re-auth frequently). Including `subscription_tier` in JWT enables quick access checks without database query on every request.
- **Alternatives Considered**:
  - Refresh token pattern: Rejected for Phase 1 (complexity), considered for Phase 2
  - Session cookies: Rejected (JWT more flexible for future mobile app)

**R7: Database Schema & Migration Strategy**
- **Question**: How to structure database schema for scalability and future Phase 2 expansion?
- **Decision**: Use Alembic for migrations. Create separate tables for each entity (User, Subscription, ChapterProgress, QuizAttempt, Streak). Use UUIDs for primary keys (enables distributed systems). Add indexes on foreign keys and frequently queried columns (user_id, chapter_id, created_at). Design schema to accommodate Phase 2 additions (e.g., adaptive_paths table).
- **Rationale**: Alembic provides version control for schema changes. UUIDs prevent ID collisions. Normalized schema reduces data duplication. Indexes ensure <100ms query times for progress lookups.
- **Alternatives Considered**:
  - NoSQL (MongoDB): Rejected (relational data fits RDBMS better, PostgreSQL free tier sufficient)
  - Single monolithic table: Rejected (poor data integrity, hard to query)

### Research Summary

**Key Technologies Validated**:
- âœ… Python 3.11 + FastAPI 0.104 + SQLAlchemy 2.0 (async stack)
- âœ… PostgreSQL 15 (Neon free tier for development)
- âœ… Redis 7 (Upstash free tier for caching)
- âœ… Cloudflare R2 (S3-compatible object storage)
- âœ… OpenAI ChatGPT Apps SDK (conversational frontend)
- âœ… JWT with HS256 (authentication/authorization)
- âœ… Alembic (database migrations)
- âœ… pytest + httpx (testing framework)

**Architecture Patterns Confirmed**:
- Repository pattern: NOT used (direct SQLAlchemy queries, simpler for Phase 1)
- Service layer: Yes (business logic separated from API routes)
- Dependency injection: Yes (FastAPI `Depends` for auth, access control)
- Caching strategy: Two-tier (Redis + R2 edge caching)
- Error handling: Structured exceptions with HTTP status codes

**Cost Projections Validated**:
- Compute: Fly.io Hobby tier ($10/month) or Railway Hobby ($5/month)
- Database: Neon free tier (0.5GB storage, sufficient for 10K users)
- Redis: Upstash free tier (10K commands/day, sufficient for Phase 1)
- Storage: R2 free tier (10GB storage, 1M reads/month) â†’ $5/month at scale
- **Total**: $15-20/month for 10K users â†’ **$0.0015-0.002/user/month** âœ… Under target

---

*All research questions resolved. Proceeding to Phase 1: Design & Contracts.*

